\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mikolov2013efficient}
\citation{pennington2014glove}
\citation{hinton2012improving}
\bibstyle{acl_natbib}
\bibdata{anthology,acl2021}
\bibcite{hinton2012improving}{{1}{2012}{{Hinton et~al.}}{{Hinton, Srivastava, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{mikolov2013efficient}{{2}{2013}{{Mikolov et~al.}}{{Mikolov, Chen, Corrado, and Dean}}}
\bibcite{pennington2014glove}{{3}{2014}{{Pennington et~al.}}{{Pennington, Socher, and Manning}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lstm_loss}{{1}{3}{Training/validation loss of the best overall model over the training epochs.\relax }{figure.caption.2}{}}
\newlabel{fig:lstm_accuracy}{{2}{3}{Training/validation accuracy of the best overall model over the training epochs.\relax }{figure.caption.3}{}}
\newlabel{word2vec_models}{{1}{3}{Performance comparison of the two architectures under different configuration scenarios using pre-trained embeddings from Word2Vec. \relax }{table.caption.4}{}}
\newlabel{embedding_models}{{2}{3}{Performance comparison of the best performing models using different types of word embeddings. \relax }{table.caption.5}{}}
\newlabel{lstm_hparams}{{3}{3}{List of hyperparameters of the best performing BiLSTM model after the hyperparameter tuning phase. \relax }{table.caption.6}{}}
\newlabel{fig:cf}{{3}{3}{Normalized confusion matrix for the best performing LSTM model using Word2Vec embeddings.\relax }{figure.caption.7}{}}
\newlabel{fig:architecture}{{4}{4}{Overview of the BiLSTM model architecture that takes a sentence pair as input, encodes them through an embedding layer and aggregates the BiLSTM encodings over the sequence lengths. Ultimately, the two representations are concatenated and fed to two fully connected layers to predict the final decision.\relax }{figure.caption.8}{}}
\gdef \@abspage@last{4}
